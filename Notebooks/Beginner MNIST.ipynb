{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>MNIST For ML Beginners</h1>\n",
    "    <h3>Interactive IPython Notebook</h3>\n",
    "    <br/>\n",
    "    Source: https://www.tensorflow.org/versions/r0.8/tutorials/mnist/beginners/index.html\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of 50 training examples from the MNIST training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = mnist.train.next_batch(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset has thousands of 28 X 28 greyscale pixel images of alpabetical characters. They are unrolled into 784 length rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,) 784\n"
     ]
    }
   ],
   "source": [
    "print( batch[0][0].shape, 28 * 28 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First image in our batch of training examples alongside the one-hot vector classification/label. A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQyjxQ6h/AdzwgYFBiQXqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d21a4bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "firstIMG = batch[0][1].reshape((28, 28))\n",
    "secondIMG = batch[0][2].reshape((28, 28))\n",
    "\n",
    "plt.axis(\"off\")\n",
    "\n",
    "imgplot = plt.imshow(firstIMG, cmap=cm.gray)\n",
    "\n",
    "batch[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second image in our batch of training examples alongside the one-hot classification vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d21a4b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(secondIMG , cmap=cm.gray)\n",
    "plt.axis(\"off\")\n",
    "batch[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Softmax Regression</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = softmax(Wx+b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Clear the graph from prior sessions. A ipython quirk. \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Hidden') as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, 784],name='input')\n",
    "    W = tf.Variable(tf.zeros([784, 10]),name='weights')\n",
    "    b = tf.Variable(tf.zeros([10]),name='biases')\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Cross-Entropy as a Cost Function</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>$$H_{y'}(y) = - \\sum_{i}y'_i  log(y_i)$$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>$$H(X) = \\sum_{i=1}^m p(x_i)log( \\frac{1}{p(x_i)}  ) \\to - \\sum_{i=1}^m x_i  log(x_i)$$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where y is our predicted probability distribution, and yâ€² is the true distribution (the one-hot vector we'll input). In some rough sense, the cross-entropy is measuring how inefficient our predictions are for describing the truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement cross-entropy we need to first add a new placeholder to input the correct answers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, tf.log computes the logarithm of each element of y. Next, we multiply each element of y_ with the corresponding element of tf.log(y). Then tf.reduce_sum adds the elements in the second dimension of y, due to the reduction_indices=[1] parameter. Finally, tf.reduce_mean computes the mean over all the examples in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we ask TensorFlow to minimize cross_entropy using the gradient descent algorithm with a learning rate of 0.5. Gradient descent is a simple procedure, where TensorFlow simply shifts each variable a little bit in the direction that reduces the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our model set up to train. One last thing before we launch it, we have to add an operation to initialize the variables we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now launch the model in a Session, and run the operation that initializes the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model, let's get TensorBoard up and running. Go to your commandline and CD into the directory that contains this notebook. Activate your tensorflow virtualenv. Then issue the following console command to launch TensorBoard: \n",
    "\n",
    "```\n",
    "tensorboard --logdir=log_beginner_minst\n",
    "\n",
    "```\n",
    "\n",
    "You should get something like this: \n",
    "\n",
    "```\n",
    "Starting TensorBoard 16 on port 6006\n",
    "(You can navigate to http://0.0.0.0:6006)\n",
    "```\n",
    "\n",
    "Open up a web browser and navigate to the url specified. \n",
    "\n",
    "Let's now visualize our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to remove a directory: log_beginner_minst/run1/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fc051bd23ce3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Andre\\Anaconda3\\envs\\TF_GPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mdelete_recursively\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    364\u001b[0m   \"\"\"\n\u001b[0;32m    365\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Andre\\Anaconda3\\envs\\TF_GPU\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Andre\\Anaconda3\\envs\\TF_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    467\u001b[0m           \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    470\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to remove a directory: log_beginner_minst/run1/"
     ]
    }
   ],
   "source": [
    "summaries_dir = \"log_beginner_minst/run1/\"\n",
    "\n",
    "if tf.gfile.Exists(summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(summaries_dir)\n",
    "    tf.gfile.MakeDirs(summaries_dir)\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(summaries_dir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train -- we'll run the training step 1000 times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100000\n",
      "Batch 200000\n",
      "Batch 300000\n",
      "Batch 400000\n",
      "Batch 500000\n",
      "Batch 600000\n",
      "Batch 700000\n",
      "Batch 800000\n",
      "Batch 900000\n",
      "Batch 1000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) \n",
    "    \n",
    "    if( (i+1)*100 % 100000 == 0):\n",
    "        print(\"Batch %i\"% ( (i+1)*100) )\n",
    "        #print(\"One example: \",batch_xs[0],batch_ys[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis. For example, tf.argmax(y,1) is the label our model thinks is most likely for each input, while tf.argmax(y_,1) is the true label. We can use tf.equal to check if our prediction matches the truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...,  True  True  True]\n",
      "0.9196\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "correctPredictionBools = sess.run(correct_prediction, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "\n",
    "print(correctPredictionBools)\n",
    "print(sum(correctPredictionBools)/float(len(correctPredictionBools)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
